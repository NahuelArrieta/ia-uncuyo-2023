# Trábajo Práctico 1

## 1. A partir del capítulo 26 de AIMA  (3er ta edición), se deberá desarrollar un resumen sobre los conceptos más importantes volcados en el capítulo.

<h3 style="text-decoration:underline"> Inteligencia Artificial Débil <h3>

El desarrolllo de al Inteligencia Artificial trae consigo la pregunta de si las máquinas son capaces de pensar como el ser humano o simplemente simular este comportamiento. La hipótesis de la **IA débil** responde a esto que las computadoras no poseen esta capacidad.

Algunos cientificos de la computación establecen que este interrogante es irrelevante. Dikjstra dice que esta pregunta es análogo a cuestionar si un submarino es capaz de nadar.
Mientras que Turing propuso, en su lugar, un test de inteligencia conductual. El mismo se basa en establecer una conversación con humano durante 5 minutos. Si el usuario no es capaz de diferenciarla de un humano, entonces la computadora pasó el test. 

El **argumento de la incapacidad** establece que hay ciertas cosas que las computadoras no pueden hacer, por ejemplo: ser amable, ingenioso, tener iniciativa, enamorarse, entre otros.
Sin embargo, pueden hacer otras cosas complejas, incluso mejor que los humanos: jugar ajedrez, diagnosticar enfermedades, manejar autos. 

Otro argumento viene de la mano del **Teorema de la incompletitud de Gödel**, ya que las computadoras al ser sistemas formales están limitadas por este teorema. No obstante, esta afirmación tiene los siguientes problemas:
- El arguento se basa en que las computadoras son sistemas formales por ser equivalentes a las Máquinas de Turing, pero las primeras son finitas y las últimas infinitas
- Un agente puede no establecer el valor de verdad de una preposición que otros agentes sí.
- No hay evidencia de que los humanos sean inmunes a estas limitaciones.

El **argumento de la informalidad** afirma que el comportamiento humano es demasiado complejo para ser capturado por un conjunto de reglas (qualification problem).

<h3 style="text-decoration:underline"> Inteligencia Artificial Fuerte <h3>

Muchos filósofos establecen que si una computadora pasa el Test de Turing no significa necesariamente que esté pensando, sino que esta simulando hacerlo.

Para que una computadora pueda pensar tiene que se consciente de su estado mental, sentir emociones, y tener creencias y deseos. La objeción a este argumento por parte de Turing es que no existe ninguna evidencia directa de los estados mentales de otros humanos.

John Searle plantea que si las simulaciones por computadora de tormentas no nos mojan, entonces una simulación del pensamiento no es pensamiento. Sin embargo, una simulación por computadora de la suma es suma, y que una de ajedrez es ajedrez. lo que da lugar a la siguiente pregunta: ¿Los procesos mentales se parecen más a tormentas o más a la suma?

La teoría monista de la mente (fisicalismo) afirma que la mente no está separada del cuerpo y  que los estados mentales son estados físicos. Esto permite, al menos en principio, la posibilidad de una IA fuerte; pero resulta difícil explicar cómo los estados físicos pueden ser simultáneamente estados mentales.

Imagina que tu cerebro es retirado de tu cuerpo al nacer y colocado en un tanque que mantiene tu cerebro, permitiendo su crecimiento y desarrollo. Al mismo tiempo, señales electrónicas son enviadas a tu cerebro desde una simulación por computadora de un mundo ficticio, y las señales motoras de tu cerebro son interceptadas y usadas para modificar la simulación según sea necesario. La vida simulada que vives replica exactamente la vida que habrías vivido si tu cerebro no hubiera sido colocado en el tanque. Así, podrías tener un estado cerebral idéntico al de alguien que realmente está comiendo una hamburguesa real, pero sería literalmente falso decir que tienes el estado mental de "saber que se está comiendo una hamburguesa". No estás comiendo una hamburguesa, ni siquiera has experimentado una hamburguesa, y por lo tanto, no podrías tener ese estado mental.

Este ejemplo parece contradecir la idea de que los estados cerebrales determinan los estados mentales. Una manera de resolver el dilema es afirmar que el contenido de los estados mentales puede interpretarse desde dos perspectivas diferentes:

- La vista de "contenido amplio" lo interpreta desde el punto de vista de un observador externo omnisciente con acceso a toda la situación.
- El "contenido estrecho" considera solo el estado cerebral. Simplemente no tiene sentido decir que si un sistema de IA está realmente pensando depende de condiciones fuera de ese sistema.


La teoría del **funcionalismo** dice que un estado mental es cualquier condición causal intermedia entre entrada y salida. Un experimento propone reemplazar gradulamente todas las neuronas de alguien por dispositivos electrónicos, y las posibles conclusiones son las siguientes:

1. Los mecanismos causales de la conciencia que generan este tipo de salidas en los cerebros normales siguen funcionando en la versión electrónica, que por lo tanto es consciente.
2. Los acontecimientos mentales conscientes en el cerebro normal no tienen conexión causal con la conducta y no están presentes en el cerebro electrónico, que por tanto no es consciente.
3. El experimento es imposible.

El **naturalismo biológico** dice que los estados mentales son características emergentes de alto nivel son causadas por procesos físicos de bajo nivel en las neuronas, y son las propiedades de las neuronas las que importan. Afirma, también, que ejecutar el programa apropiado (es decir, tener las salidas correctas) no es una condición suficiente para ser una mente.

En el ejemplo del **cuarto chino** un ser humano que solo entiende inglés está en un cuarto equipado con un manual de instrucciones escrito en inglés. A través de una abertura en el cuarto aparecen trozos de papel con símbolos indescifrables. El  humano encuentra símbolos coincidentes en el manual de instrucciones y sigue las indicaciones. Las instrucciones pueden incluir escribir símbolos en nuevos trozos de papel, encontrar símbolos en las pilas, reorganizar las pilas, y así sucesivamente. Eventualmente, las instrucciones harán que uno o más símbolos sean transcritos en un trozo de papel que se envía de vuelta al mundo exterior.


<h3 style="text-decoration:underline"> La ética y los riesgos de desarrollar Inteligencia Artificial. <h3>

- <p style="text-decoration:underline"> Las personas podrían perder sus empleos debido a la automatización:</p> 
Existe la preocupación de que ciertas tareas sean reemplazados por máquinas y sistemas automatizados. Esto podría llevar a la pérdida de trabajos para muchas personas cuyas tareas pueden ser realizadas más eficiente por la IA.

- <p style="text-decoration:underline"> Las personas podrían tener demasiado tiempo libre:</p>
Si la automatización se implementa ampliamente, es posible que algunas personas tengan más tiempo libre debido a la reducción de ciertas tareas laborales. 

- <p style="text-decoration:underline"> Las personas podrían perder su sentido de ser únicas:</p> 
A medida que las máquinas se vuelven más capaces de realizar tareas complejas, algunas personas podrían enfrentar desafíos para encontrar su lugar en un mundo donde la tecnología tiene un papel más importante.

- <p style="text-decoration:underline"> Los sistemas de IA podrían ser utilizados para fines no deseados:</p> 
Los sistemas de IA pueden ser utilizados para propagar información falsa, influir en la opinión pública o incluso para llevar a cabo ataques cibernéticos. 

- <p style="text-decoration:underline"> El uso de sistemas de IA podría resultar en una pérdida de responsabilidad:</p>
A medida que los sistemas de inteligencia artificial toman decisiones y realizan tareas, puede resultar difícil determinar quién es responsable en caso de errores o consecuencias negativas. 

- <p style="text-decoration:underline"> El éxito de la IA podría significar el fin de la raza humana:</p>
Si la inteligencia artificial alcanza un nivel de desarrollo tan avanzado que supera la inteligencia humana, podría plantear desafíos existenciales sobre posibles escenarios en los que la IA podría volverse incontrolable o superar a los humanos en términos de capacidad intelectua.

## 2. Realizar un mapa mental de los conceptos y sus relaciones.
Link: https://www.mindomo.com/es/mindmap/c57b62ac72db498d8049ffc08313ead2