# Trábajo Práctico 1

## 1. A partir del capítulo 26 de AIMA  (3er ta edición), se deberá desarrollar un resumen sobre los conceptos más importantes volcados en el capítulo.

<h3 style="text-decoration:underline"> Inteligencia Artificial Débil <h3>

El desarrolllo de al Inteligencia Artificial trae consigo la pregunta de si las máquinas son capaces de pensar como el ser humano o simplemente simular este comportamiento. La hipótesis de la **IA débil** responde a esto que las computadoras no poseen esta capacidad.

Algunos cientificos de la computación establecen que este interrogante es irrelevante. Dikjstra dice que esta pregunta es análogo a cuestionar si un submarino es capaz de nadar.
Mientras que Turing propuso, en su lugar, un test de inteligencia conductual. El mismo se basa en establecer una conversación con humano durante 5 minutos. Si el usuario no es capaz de diferenciarla de un humano, entonces la computadora pasó el test. 

El **argumento de la incapacidad** establece que hay ciertas cosas que las computadoras no pueden hacer, por ejemplo: ser amable, ingenioso, tener iniciativa, enamorarse, entre otros.
Sin embargo, pueden hacer otras cosas complejas, incluso mejor que los humanos: jugar ajedrez, diagnosticar enfermedades, manejar autos. 

Otro argumento viene de la mano del **Teorema de la incompletitud de Gödel**, ya que las computadoras al ser sistemas formales están limitadas por este teorema. No obstante, esta afirmación tiene los siguientes problemas:
- El arguento se basa en que las computadoras son sistemas formales por ser equivalentes a las Máquinas de Turing, pero las primeras son finitas y las últimas infinitas
- Un agente puede no establecer el valor de verdad de una preposición que otros agentes sí.
- No hay evidencia de que los humanos sean inmunes a estas limitaciones.

El **argumento de la informalidad** afirma que el comportamiento humano es demasiado complejo para ser capturado por un conjunto de reglas (qualification problem).

<h3 style="text-decoration:underline"> Inteligencia Artificial Fuerte <h3>

Muchos filósofos establecen que si una computadora pasa el Test de Turing no significa necesariamente que esté pensando, sino que esta simulando hacerlo.

Para que una computadora pueda pensar tiene que se consciente de su estado mental, sentir emociones, y tener creencias y deseos. La objeción a este argumento por parte de Turing es que no existe ninguna evidencia directa de los estados mentales de otros humanos.

John Searle plantea que si las simulaciones por computadora de tormentas no nos mojan, entonces una simulación del pensamiento no es pensamiento. Sin embargo, una simulación por computadora de la suma es suma, y que una de ajedrez es ajedrez. lo que da lugar a la siguiente pregunta: ¿Los procesos mentales se parecen más a tormentas o más a la suma?

La teoría monista de la mente (fisicalismo) afirma que la mente no está separada del cuerpo y  que los estados mentales son estados físicos. Esto permite, al menos en principio, la posibilidad de una IA fuerte; pero resulta difícil explicar cómo los estados físicos pueden ser simultáneamente estados mentales.

Imagina que tu cerebro es retirado de tu cuerpo al nacer y colocado en un tanque que mantiene tu cerebro, permitiendo su crecimiento y desarrollo. Al mismo tiempo, señales electrónicas son enviadas a tu cerebro desde una simulación por computadora de un mundo ficticio, y las señales motoras de tu cerebro son interceptadas y usadas para modificar la simulación según sea necesario. La vida simulada que vives replica exactamente la vida que habrías vivido si tu cerebro no hubiera sido colocado en el tanque. Así, podrías tener un estado cerebral idéntico al de alguien que realmente está comiendo una hamburguesa real, pero sería literalmente falso decir que tienes el estado mental de "saber que se está comiendo una hamburguesa". No estás comiendo una hamburguesa, ni siquiera has experimentado una hamburguesa, y por lo tanto, no podrías tener ese estado mental.

Este ejemplo parece contradecir la idea de que los estados cerebrales determinan los estados mentales. Una manera de resolver el dilema es afirmar que el contenido de los estados mentales puede interpretarse desde dos perspectivas diferentes:
- La vista de "contenido amplio" lo interpreta desde el punto de vista de un observador externo omnisciente con acceso a toda la situación.
- El "contenido estrecho" considera solo el estado cerebral. Simplemente no tiene sentido decir que si un sistema de IA está realmente pensando depende de condiciones fuera de ese sistema.

